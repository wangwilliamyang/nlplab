PRAPROLOG - JAVA
This is a port of a python prototype for doing RWR calculations over graphs 
generated by prolog prover processes.

The python code is on raff:
cvsroot=raff:/usr1/cvsroot pyhack/pprolog
and was written by wcohen.

The java port was done by krivard. In places where python makes use of multiple 
inheritance, I have made a "reasonable" choice of where to put the necessary 
methods, and made a note in the javadoc.

The Java port is much faster than python, and was pursued with parallelization 
in mind.

ACQUIRING CODE & SETTING UP YOUR ENVIRONMENT
============================================

The python version is on cvs on raff and you have to ssh there to get it. This
means you need an ssh account on raff, and you must be in the cvs group.

user@somewhere $ ssh user@raff.ml.cmu.edu

For the python version you will need to check out the pprolog project:

user@raff $ export CVSROOT=/usr1/cvsroot
user@raff $ cvs co pyhacks/pprolog

as well as some utility code:

user@raff $ cvs co pyutil
user@raff $ mkdir raff-site-packages
user@raff $ cp /usr0/wcohen/code/pthon-installation/site-packages/pyparsing.py
raff-site-packages/

From here you can copy that collection of code wherever you prefer to work.

To run the code in pprolog you will need to add the pyutil and
raff-site-packages directories to the PYTHONPATH shell environment
variable, something like this:

export PYTHONPATH=~/software/python/pyutil:~/software/python/raff-site-packages

(replace those paths with wherever you've put them)



The java version is on svn on curtis. If you only need read access, do

$ svn co svn://curtis.ml.cmu.edu/Praprolog

if you think you will be contributing code to the project, email me at
krivard@cs.cmu.edu so I can get you write access to that machine.


USING PRAPROLOG
===============

ProPPR is composed of two basic processes: inference, and learning.

We covered Learning in the UAI'13 paper. We will cover Inference next.

== Learning ==

The main() methods in the java version for learning are called *Trainer.
  edu.cmu.ml.praprolog.Trainer - Single-threaded, Java Collections-based
  edu.cmu.ml.praprolog.MultithreadedTrainer - Multi-threaded, Java Collections-based
  edu.cmu.ml.praprolog.trove.Trainer - Single-threaded, GNU Trove -based (2ce as fast)
  edu.cmu.ml.praprolog.trove.MultithreadedTrainer - Multi-threaded, GNU Trove -based (2ce as fast)

Usually I run from the pprolog directory, using/modifying the makefile
there. An example target from the python Makefile which has been
converted to use the java package for training is:

hmtextcat:
        python examplecooker.py --programFiles
demo/textcat/textcat.rules:demo/textcat/labels.facts:demo/textcat/words.graph
--data demo/textcat/train.data --prover 'prv.dprProver(maxDepth=4)'
--output demo/textcat/textcat.cooked
        java edu.cmu.ml.praprolog.MultithreadedTrainer
demo/textcat/textcat.cooked demo/textcat/textcat.multi.params
--threads 4
        python trainer.py --programFiles
demo/textcat/textcat.rules:demo/textcat/labels.facts:demo/textcat/words.graph
--params demo/textcat/textcat.multi.params --testData
demo/textcat/test.data --prover 'prv.dprProver(maxDepth=4)'
--traceLosses

A good value for --threads is one less than the number of cores your
computer has, which you can often find by doing:
  user@somewhere $ grep -c processor /proc/cpuinfo

== Inference ==

The main() method in the java version for inference is:
  edu.cmu.ml.praprolog.ExampleCooker

It takes roughly the same options as its python equivalent, except it requires
compiled versions of the rules and facts files, as Java lacks a parser.

Compile a rules file using rulecompiler.py.

Compile a facts file using sed.



BUGS
====

EDGE HASH COLLISION BUG

The edu.cmu.ml.praprolog.trove tree uses primitive int keys as nodes exclusively.
To speed up Edge maps I had to reimplement the hash computation, and discovered
some collisions in some datasets. I fixed the hash function until I stopped 
seeing collision messages, but your dataset may vary. A collision message looks
like this:

WARN Overwriting existing features for u(6):v(156) (normally we expect each edge to only be added once)

...with the true node names and IDs subbed in for u and v. If you see a collision
message, email krivard@cs.cmu.edu with the test of the message and the cooked 
dataset you were running on.

DICTIONARY GET BUG

There is a sneaky null pointer exception bug in the multithreaded version which
is difficult to provoke. I believe I have fixed it, but if you see a stack trace
like this in the WARN logs, email krivard@cs.cmu.edu with the trace and the
options you were running with. -thanks

Anything starting with Dictionary.safeGet() is fair game -- here is an example:

java.lang.NullPointerException
       at edu.cmu.ml.praprolog.util.Dictionary.safeGet(Dictionary.java:65)
       at edu.cmu.ml.praprolog.learn.SRW.edgeWeight(SRW.java:65)
       at edu.cmu.ml.praprolog.learn.SRW.walkOnceUsingFeatures(SRW.java:125)
       at edu.cmu.ml.praprolog.learn.SRW.rwrUsingFeatures(SRW.java:94)
       at edu.cmu.ml.praprolog.learn.L2PosNegLossTrainedSRW.gradient(L2PosNegLossTrainedSRW.java:24)
       at edu.cmu.ml.praprolog.learn.L2PosNegLossTrainedSRW.gradient(L2PosNegLossTrainedSRW.java:1)
       at edu.cmu.ml.praprolog.learn.SRW.trainOnExample(SRW.java:257)
       at edu.cmu.ml.praprolog.MultithreadedTrainer$TrainerThread.run(MultithreadedTrainer.java:131)
       at java.lang.Thread.run(Thread.java:722)
       

EXCEPTION RECOVERY IS SATISFACTORY BUT NOT PERFECT

If the above NPE or any other exception happens during training, the code is 
designed to pick up where it left off. This may result in some examples being
trained twice in some epochs, which in most applications doesn't make much
difference in the final trained params. It will, however, probably wreck any
traceLosses calculations.

If you notice a patterns of exceptions, let us know. If you notice exceptions
causing a substantial change in trained params values, let us know. If you need
accurate traceLosses values in exception-prone conditions, let us know. 